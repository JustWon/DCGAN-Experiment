{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20170702 실험\n",
    "\n",
    "더 많은 Places 데이터셋에 대해서 학습한 DCGAN모델을 이용하여 피쳐를 만들고 다시 해본다.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "generator/g_h0_lin/Matrix:0 (float32_ref 100x8192) [819200, bytes: 3276800]\n",
      "generator/g_h0_lin/bias:0 (float32_ref 8192) [8192, bytes: 32768]\n",
      "generator/g_bn0/beta:0 (float32_ref 512) [512, bytes: 2048]\n",
      "generator/g_bn0/gamma:0 (float32_ref 512) [512, bytes: 2048]\n",
      "generator/g_h1/w:0 (float32_ref 5x5x256x512) [3276800, bytes: 13107200]\n",
      "generator/g_h1/biases:0 (float32_ref 256) [256, bytes: 1024]\n",
      "generator/g_bn1/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
      "generator/g_bn1/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
      "generator/g_h2/w:0 (float32_ref 5x5x128x256) [819200, bytes: 3276800]\n",
      "generator/g_h2/biases:0 (float32_ref 128) [128, bytes: 512]\n",
      "generator/g_bn2/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "generator/g_bn2/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "generator/g_h3/w:0 (float32_ref 5x5x64x128) [204800, bytes: 819200]\n",
      "generator/g_h3/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "generator/g_bn3/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "generator/g_bn3/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "generator/g_h4/w:0 (float32_ref 5x5x3x64) [4800, bytes: 19200]\n",
      "generator/g_h4/biases:0 (float32_ref 3) [3, bytes: 12]\n",
      "discriminator/d_h0_conv/w:0 (float32_ref 5x5x3x64) [4800, bytes: 19200]\n",
      "discriminator/d_h0_conv/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "discriminator/d_h1_conv/w:0 (float32_ref 5x5x64x128) [204800, bytes: 819200]\n",
      "discriminator/d_h1_conv/biases:0 (float32_ref 128) [128, bytes: 512]\n",
      "discriminator/d_bn1/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "discriminator/d_bn1/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "discriminator/d_h2_conv/w:0 (float32_ref 5x5x128x256) [819200, bytes: 3276800]\n",
      "discriminator/d_h2_conv/biases:0 (float32_ref 256) [256, bytes: 1024]\n",
      "discriminator/d_bn2/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
      "discriminator/d_bn2/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
      "discriminator/d_h3_conv/w:0 (float32_ref 5x5x256x512) [3276800, bytes: 13107200]\n",
      "discriminator/d_h3_conv/biases:0 (float32_ref 512) [512, bytes: 2048]\n",
      "discriminator/d_bn3/beta:0 (float32_ref 512) [512, bytes: 2048]\n",
      "discriminator/d_bn3/gamma:0 (float32_ref 512) [512, bytes: 2048]\n",
      "discriminator/d_h3_lin/Matrix:0 (float32_ref 8192x1) [8192, bytes: 32768]\n",
      "discriminator/d_h3_lin/bias:0 (float32_ref 1) [1, bytes: 4]\n",
      "Total size of variables: 9451908\n",
      "Total bytes of variables: 37807632\n",
      " [*] Reading checkpoints...\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/PatchofPlaces_64_64_64/DCGAN.model-393502\n",
      " [*] Success to read DCGAN.model-393502\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from model import DCGAN\n",
    "from utils import pp, visualize, to_json, show_all_variables\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import sys\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_integer(\"epoch\", 25, \"Epoch to train [25]\")\n",
    "flags.DEFINE_float(\"learning_rate\", 0.0002, \"Learning rate of for adam [0.0002]\")\n",
    "flags.DEFINE_float(\"beta1\", 0.5, \"Momentum term of adam [0.5]\")\n",
    "flags.DEFINE_integer(\"train_size\", np.inf, \"The size of train images [np.inf]\")\n",
    "flags.DEFINE_integer(\"batch_size\", 64, \"The size of batch images [64]\")\n",
    "flags.DEFINE_integer(\"input_height\", 64, \"The size of image to use (will be center cropped). [108]\")\n",
    "flags.DEFINE_integer(\"input_width\", None,\n",
    "                     \"The size of image to use (will be center cropped). If None, same value as input_height [None]\")\n",
    "flags.DEFINE_integer(\"output_height\", 64, \"The size of the output images to produce [64]\")\n",
    "flags.DEFINE_integer(\"output_width\", None,\n",
    "                     \"The size of the output images to produce. If None, same value as output_height [None]\")\n",
    "flags.DEFINE_string(\"dataset\", \"PatchofPlaces\", \"The name of dataset [celebA, mnist, lsun]\")\n",
    "flags.DEFINE_string(\"input_fname_pattern\", \"*/*.jpg\", \"Glob pattern of filename of input images [*]\")\n",
    "flags.DEFINE_string(\"checkpoint_dir\", \"checkpoint\", \"Directory name to save the checkpoints [checkpoint]\")\n",
    "flags.DEFINE_string(\"sample_dir\", \"samples\", \"Directory name to save the image samples [samples]\")\n",
    "flags.DEFINE_boolean(\"train\", False, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"crop\", False, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"visualize\", False, \"True for visualizing, False for nothing [False]\")\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "\n",
    "\n",
    "pp.pprint(flags.FLAGS.__flags)\n",
    "\n",
    "if FLAGS.input_width is None:\n",
    "    FLAGS.input_width = FLAGS.input_height\n",
    "if FLAGS.output_width is None:\n",
    "    FLAGS.output_width = FLAGS.output_height\n",
    "\n",
    "if not os.path.exists(FLAGS.checkpoint_dir):\n",
    "    os.makedirs(FLAGS.checkpoint_dir)\n",
    "if not os.path.exists(FLAGS.sample_dir):\n",
    "    os.makedirs(FLAGS.sample_dir)\n",
    "\n",
    "# gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "run_config = tf.ConfigProto()\n",
    "run_config.gpu_options.allow_growth = True\n",
    "\n",
    "\n",
    "sess = tf.Session(config=run_config)\n",
    "\n",
    "dcgan = DCGAN(\n",
    "    sess,\n",
    "    input_width=FLAGS.input_width,\n",
    "    input_height=FLAGS.input_height,\n",
    "    output_width=FLAGS.output_width,\n",
    "    output_height=FLAGS.output_height,\n",
    "    batch_size=FLAGS.batch_size,\n",
    "    sample_num=FLAGS.batch_size,\n",
    "    dataset_name=FLAGS.dataset,\n",
    "    input_fname_pattern=FLAGS.input_fname_pattern,\n",
    "    crop=FLAGS.crop,\n",
    "    checkpoint_dir=FLAGS.checkpoint_dir,\n",
    "    sample_dir=FLAGS.sample_dir)\n",
    "\n",
    "show_all_variables()\n",
    "\n",
    "if not dcgan.load(FLAGS.checkpoint_dir)[0]:\n",
    "    raise Exception(\"[!] Train a model first, then run test mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layer_extraction(dcgan, file_names):\n",
    "    return dcgan.get_feature(FLAGS, file_names)\n",
    "    \n",
    "def maxpooling(disc):\n",
    "    kernel_stride_size = 4\n",
    "    maxpooling = [\n",
    "        tf.nn.max_pool(disc[i],ksize=[1,2**(4-i),2**(4-i),1],\n",
    "                       strides=[1,2**(4-i),2**(4-i),1],padding='SAME')\n",
    "        for i in range(4)\n",
    "    ]\n",
    "\n",
    "#     tf.global_variables_initializer().run()\n",
    "    maxpool_result = sess.run(maxpooling)\n",
    "\n",
    "#     for idx in range(4):\n",
    "#         print(idx, maxpool_result[idx].shape)\n",
    "\n",
    "    return maxpool_result\n",
    "\n",
    "def flatten(disc):\n",
    "    flatten = [\n",
    "        tf.reshape(disc[i],[64, -1])\n",
    "        for i in range(4)\n",
    "    ]\n",
    "#     tf.global_variables_initializer().run()\n",
    "    flatten_result = sess.run(flatten)\n",
    "    \n",
    "    return flatten_result\n",
    "\n",
    "def concat(disc):\n",
    "    concat = tf.concat(disc,1)\n",
    "\n",
    "#     tf.global_variables_initializer().run()\n",
    "    concat_result = sess.run(concat)\n",
    "    \n",
    "    return concat_result\n",
    "\n",
    "def feature_ext_GAN(file_names):\n",
    "    \n",
    "    ret = layer_extraction(dcgan, file_names)\n",
    "    ret = maxpooling(ret)\n",
    "    ret = flatten(ret)\n",
    "    ret = concat(ret)\n",
    "        \n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400 ~ 2500\n",
      "total: 22435\n",
      "..............................................................................................................................................................................................................................................................................................................................................................done.\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components = 128)\n",
    "\n",
    "for term in [24]:\n",
    "    print('%d ~ %d' % (100*term,100*(term+1)))\n",
    "    \n",
    "    disc_list = []\n",
    "    batch_list = []\n",
    "    file_names = []\n",
    "    \n",
    "    for idx in range(100*term,100*(term+1)):\n",
    "        patch_path =\"/media/dongwonshin/Ubuntu Data/Datasets/FAB-MAP/Image Data/City Centre/patches/#300/\"\n",
    "        data = sorted(glob(\"%s/%04d/*.jpg\" % (patch_path, idx)))\n",
    "#         patch_path =\"/media/dongwonshin/Ubuntu Data/Datasets/Places365/Large_images/val_large/patches\"\n",
    "#         data = glob(\"%s/Places365_val_%08d/*.jpg\" % (patch_path, idx))\n",
    "        file_names.append(data)\n",
    "\n",
    "    file_names=np.concatenate(file_names)\n",
    "    print('total:',len(file_names))\n",
    "#     print(file_names)\n",
    "\n",
    "    for idx in range(0, len(file_names)-64,64):\n",
    "        batch_files = file_names[idx: idx+64]\n",
    "\n",
    "        disc = feature_ext_GAN(batch_files)\n",
    "\n",
    "        disc_list.append(disc)\n",
    "        batch_list.append(batch_files)\n",
    "        sys.stdout.write('.')\n",
    "\n",
    "    final_disc_list = np.concatenate(disc_list)\n",
    "    final_batch_list = np.concatenate(batch_list)\n",
    "    \n",
    "    X = np.array(final_disc_list)\n",
    "    pca.fit(X)\n",
    "    final_disc_list = pca.transform(X)\n",
    "    \n",
    "    for idx, name in enumerate(final_batch_list):\n",
    "        output_filename = '/media/dongwonshin/Ubuntu Data/Datasets/FAB-MAP/Image Data/City Centre/descs/20170702/' + (name.split('/')[-2])+'.desc'\n",
    "#         output_filename = '/media/dongwonshin/Ubuntu Data/Datasets/Places365/Large_images/val_large/descs/20170702/' + (name.split('/')[-2])+'.desc'\n",
    "        \n",
    "\n",
    "        with open(output_filename,'at') as fp:\n",
    "            for v in final_disc_list[idx]:\n",
    "                fp.write('%f ' % v)\n",
    "            fp.write('\\n')\n",
    "\n",
    "print('done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
