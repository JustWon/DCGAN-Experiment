{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "generator/g_h0_lin/Matrix:0 (float32_ref 100x8192) [819200, bytes: 3276800]\n",
      "generator/g_h0_lin/bias:0 (float32_ref 8192) [8192, bytes: 32768]\n",
      "generator/g_bn0/beta:0 (float32_ref 512) [512, bytes: 2048]\n",
      "generator/g_bn0/gamma:0 (float32_ref 512) [512, bytes: 2048]\n",
      "generator/g_h1/w:0 (float32_ref 5x5x256x512) [3276800, bytes: 13107200]\n",
      "generator/g_h1/biases:0 (float32_ref 256) [256, bytes: 1024]\n",
      "generator/g_bn1/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
      "generator/g_bn1/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
      "generator/g_h2/w:0 (float32_ref 5x5x128x256) [819200, bytes: 3276800]\n",
      "generator/g_h2/biases:0 (float32_ref 128) [128, bytes: 512]\n",
      "generator/g_bn2/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "generator/g_bn2/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "generator/g_h3/w:0 (float32_ref 5x5x64x128) [204800, bytes: 819200]\n",
      "generator/g_h3/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "generator/g_bn3/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "generator/g_bn3/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "generator/g_h4/w:0 (float32_ref 5x5x3x64) [4800, bytes: 19200]\n",
      "generator/g_h4/biases:0 (float32_ref 3) [3, bytes: 12]\n",
      "discriminator/d_h0_conv/w:0 (float32_ref 5x5x3x64) [4800, bytes: 19200]\n",
      "discriminator/d_h0_conv/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "discriminator/d_h1_conv/w:0 (float32_ref 5x5x64x128) [204800, bytes: 819200]\n",
      "discriminator/d_h1_conv/biases:0 (float32_ref 128) [128, bytes: 512]\n",
      "discriminator/d_bn1/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "discriminator/d_bn1/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "discriminator/d_h2_conv/w:0 (float32_ref 5x5x128x256) [819200, bytes: 3276800]\n",
      "discriminator/d_h2_conv/biases:0 (float32_ref 256) [256, bytes: 1024]\n",
      "discriminator/d_bn2/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
      "discriminator/d_bn2/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
      "discriminator/d_h3_conv/w:0 (float32_ref 5x5x256x512) [3276800, bytes: 13107200]\n",
      "discriminator/d_h3_conv/biases:0 (float32_ref 512) [512, bytes: 2048]\n",
      "discriminator/d_bn3/beta:0 (float32_ref 512) [512, bytes: 2048]\n",
      "discriminator/d_bn3/gamma:0 (float32_ref 512) [512, bytes: 2048]\n",
      "discriminator/d_h3_lin/Matrix:0 (float32_ref 8192x1) [8192, bytes: 32768]\n",
      "discriminator/d_h3_lin/bias:0 (float32_ref 1) [1, bytes: 4]\n",
      "Total size of variables: 9451908\n",
      "Total bytes of variables: 37807632\n",
      " [*] Reading checkpoints...\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/PatchofPlaces_64_64_64/DCGAN.model-150002\n",
      " [*] Success to read DCGAN.model-150002\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "\n",
    "from model import DCGAN\n",
    "from utils import pp, visualize, to_json, show_all_variables\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_integer(\"epoch\", 25, \"Epoch to train [25]\")\n",
    "flags.DEFINE_float(\"learning_rate\", 0.0002, \"Learning rate of for adam [0.0002]\")\n",
    "flags.DEFINE_float(\"beta1\", 0.5, \"Momentum term of adam [0.5]\")\n",
    "flags.DEFINE_integer(\"train_size\", np.inf, \"The size of train images [np.inf]\")\n",
    "flags.DEFINE_integer(\"batch_size\", 64, \"The size of batch images [64]\")\n",
    "flags.DEFINE_integer(\"input_height\", 64, \"The size of image to use (will be center cropped). [108]\")\n",
    "flags.DEFINE_integer(\"input_width\", None,\n",
    "                     \"The size of image to use (will be center cropped). If None, same value as input_height [None]\")\n",
    "flags.DEFINE_integer(\"output_height\", 64, \"The size of the output images to produce [64]\")\n",
    "flags.DEFINE_integer(\"output_width\", None,\n",
    "                     \"The size of the output images to produce. If None, same value as output_height [None]\")\n",
    "flags.DEFINE_string(\"dataset\", \"PatchofPlaces\", \"The name of dataset [celebA, mnist, lsun]\")\n",
    "flags.DEFINE_string(\"input_fname_pattern\", \"*.jpg\", \"Glob pattern of filename of input images [*]\")\n",
    "flags.DEFINE_string(\"checkpoint_dir\", \"checkpoint\", \"Directory name to save the checkpoints [checkpoint]\")\n",
    "flags.DEFINE_string(\"sample_dir\", \"samples\", \"Directory name to save the image samples [samples]\")\n",
    "flags.DEFINE_boolean(\"train\", False, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"crop\", False, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"visualize\", False, \"True for visualizing, False for nothing [False]\")\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "\n",
    "\n",
    "pp.pprint(flags.FLAGS.__flags)\n",
    "\n",
    "if FLAGS.input_width is None:\n",
    "    FLAGS.input_width = FLAGS.input_height\n",
    "if FLAGS.output_width is None:\n",
    "    FLAGS.output_width = FLAGS.output_height\n",
    "\n",
    "if not os.path.exists(FLAGS.checkpoint_dir):\n",
    "    os.makedirs(FLAGS.checkpoint_dir)\n",
    "if not os.path.exists(FLAGS.sample_dir):\n",
    "    os.makedirs(FLAGS.sample_dir)\n",
    "\n",
    "# gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "run_config = tf.ConfigProto()\n",
    "run_config.gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.Session(config=run_config)\n",
    "\n",
    "dcgan = DCGAN(\n",
    "    sess,\n",
    "    input_width=FLAGS.input_width,\n",
    "    input_height=FLAGS.input_height,\n",
    "    output_width=FLAGS.output_width,\n",
    "    output_height=FLAGS.output_height,\n",
    "    batch_size=FLAGS.batch_size,\n",
    "    sample_num=FLAGS.batch_size,\n",
    "    dataset_name=FLAGS.dataset,\n",
    "    input_fname_pattern=FLAGS.input_fname_pattern,\n",
    "    crop=FLAGS.crop,\n",
    "    checkpoint_dir=FLAGS.checkpoint_dir,\n",
    "    sample_dir=FLAGS.sample_dir)\n",
    "\n",
    "show_all_variables()\n",
    "\n",
    "if not dcgan.load(FLAGS.checkpoint_dir)[0]:\n",
    "    raise Exception(\"[!] Train a model first, then run test mode\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def layer_extraction(file_names):\n",
    "    return dcgan.get_feature(FLAGS, file_names)\n",
    "    \n",
    "# disc, batch_files = layer_extraction(0,64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maxpooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def maxpooling(disc):\n",
    "    kernel_stride_size = 4\n",
    "    maxpooling = [\n",
    "        tf.nn.max_pool(disc[i],ksize=[1,2**(4-i),2**(4-i),1],\n",
    "                       strides=[1,2**(4-i),2**(4-i),1],padding='SAME')\n",
    "        for i in range(4)\n",
    "    ]\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        maxpool_result = sess.run(maxpooling)\n",
    "\n",
    "#     for idx in range(4):\n",
    "#         print(idx, maxpool_result[idx].shape)\n",
    "\n",
    "    return maxpool_result\n",
    "\n",
    "# maxpool_result = maxpooling(disc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(disc):\n",
    "    flatten = [\n",
    "        tf.reshape(disc[i],[64, -1])\n",
    "        for i in range(4)\n",
    "    ]\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        flatten_result = sess.run(flatten)\n",
    "    \n",
    "    return flatten_result\n",
    "\n",
    "#     for idx in range(4):\n",
    "#         print(idx, flatten_result[idx].shape)\n",
    "\n",
    "# flatten_result = flatten(maxpool_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat(disc):\n",
    "    concat = tf.concat(disc,1)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        concat_result = sess.run(concat)\n",
    "    return concat_result\n",
    "\n",
    "# concat_result = concat(flatten_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_ext_GAN(file_names):\n",
    "    ret = layer_extraction(file_names)\n",
    "    ret = maxpooling(ret)\n",
    "    ret = flatten(ret)\n",
    "    ret = concat(ret)\n",
    "    return ret\n",
    "\n",
    "# data = glob(os.path.join(\"/home/dongwonshin/Desktop/PatchExtractor/SIFT Patches\", \"*/*.jpg\"))\n",
    "# data.sort()\n",
    "# batch_files = data[0:64]\n",
    "\n",
    "# ret = feature_ext_GAN(batch_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    }
   ],
   "source": [
    "\n",
    "disc_list = []\n",
    "batch_list = []\n",
    "\n",
    "file_names = []\n",
    "for idx in range(9,10):\n",
    "\n",
    "    data = glob(\"/home/dongwonshin/Desktop/PatchExtractor/SIFT Patches/%04d/*.jpg\" % idx)\n",
    "    data.sort()\n",
    "    file_names.append(data)\n",
    "\n",
    "file_names =np.concatenate(file_names)\n",
    "print(len(file_names))\n",
    "\n",
    "for idx in range(0, len(file_names)-64,64):\n",
    "\n",
    "    batch_files = file_names[idx: idx+64]\n",
    "\n",
    "    disc = feature_ext_GAN(batch_files)\n",
    "    disc_list.append(disc)\n",
    "    batch_list.append(batch_files)\n",
    "    print(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_disc_list = np.concatenate(disc_list)\n",
    "final_batch_list = np.concatenate(batch_list)\n",
    "\n",
    "len(final_disc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for idx, name in enumerate(final_batch_list):\n",
    "    output_filename = 'result/' + (name.split('/')[-2])+'.desc'\n",
    "    \n",
    "    with open(output_filename,'ab') as fp:\n",
    "        for v in final_disc_list[idx]:\n",
    "            fp.write('%f ' % v)\n",
    "        fp.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow, imsave\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def my_img_show(filename):\n",
    "    img = mpimg.imread(filename)\n",
    "    plt.figure(); plt.grid(False);\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_clusters = 20\n",
    "kmeans = KMeans(n_clusters=n_clusters).fit(final_disc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_montage(file_name, image_stack):\n",
    "\n",
    "    final_montage = []\n",
    "    img_row = []\n",
    "    for n, img in enumerate(image_stack):\n",
    "        img_row.append(img)\n",
    "        if (n+1)%20 == 0:\n",
    "            final_montage.append(np.hstack(img_row))\n",
    "            img_row = []\n",
    "\n",
    "    if (len(img_row) == 0):\n",
    "        cv2.imwrite(file_name, (np.vstack(final_montage)))\n",
    "    else:\n",
    "        extra_width = 0\n",
    "        while (n+1)%20 != 0:\n",
    "            n+=1\n",
    "            extra_width+=64\n",
    "        # print(extra_width)\n",
    "        # print(np.hstack(img_row).shape)\n",
    "        extra_img = np.hstack([np.hstack(img_row), np.zeros([64, extra_width,3], dtype=np.uint8)])\n",
    "        # print(np.hstack(img_row).shape)\n",
    "        # print(extra_img.shape)\n",
    "        cv2.imwrite(file_name, (np.vstack([np.vstack(final_montage),extra_img])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class=0\n",
      "class=1\n",
      "class=2\n",
      "class=3\n",
      "class=4\n",
      "class=5\n",
      "class=6\n",
      "class=7\n",
      "class=8\n",
      "class=9\n",
      "class=10\n",
      "class=11\n",
      "class=12\n",
      "class=13\n",
      "class=14\n",
      "class=15\n",
      "class=16\n",
      "class=17\n",
      "class=18\n",
      "class=19\n"
     ]
    }
   ],
   "source": [
    "for class_id in range(0,n_clusters):\n",
    "    same_class = []\n",
    "    for idx in range(len(final_disc_list)):\n",
    "        if kmeans.labels_[idx] == class_id:\n",
    "            same_class.append(cv2.imread(final_batch_list[idx]))\n",
    "\n",
    "    print('class=%d' % class_id)\n",
    "    temp1 = []\n",
    "    for n, s in enumerate(same_class):\n",
    "        temp1.append(s)\n",
    "\n",
    "#     print(len(temp1))\n",
    "    image_montage('class=%d.jpg' % class_id, temp1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
